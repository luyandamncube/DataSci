# Sentiment Analysis

* This is done through tokenisation. 
* Given a character sequence and a defined document unit, tokenization is the task of chopping it up into pieces, called tokens , perhaps at the same time throwing away certain characters, such as punctuation. 
* A sentiment value (or score) is given to each token  using an existing lexicon.

<p align="center">
  <img src="https://lh4.googleusercontent.com/W6Fjw6dstG7IU2QvYO5IYZCIKmaPIFnWv8lzGGgspPcQCQQ6z6y3UQ_ETErwuYhXGWkKe3h93f1t5ZqZ9dbv_RBNTp0XxP5KHbHbyTlFbbpk6CLOPmXsDVh4td-jzPjiZCWOTqyh"/>
</p>
# Resources

* [What is Tokenization?](https://www.youtube.com/watch?v=vyyTpL8QKgc)
* [Twitter Sentiment Analysis](https://www.youtube.com/watch?v=o_OZdbCzHUA)
* [Sentiment Analysis - Deep Learning](https://www.youtube.com/watch?v=si8zZHkufRY&t=8s)



